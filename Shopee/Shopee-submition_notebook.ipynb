{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "robust-weapon",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-09T23:13:39.666376Z",
     "iopub.status.busy": "2021-05-09T23:13:39.665783Z",
     "iopub.status.idle": "2021-05-09T23:14:44.766750Z",
     "shell.execute_reply": "2021-05-09T23:14:44.765671Z"
    },
    "papermill": {
     "duration": 65.132482,
     "end_time": "2021-05-09T23:14:44.766916",
     "exception": false,
     "start_time": "2021-05-09T23:13:39.634434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.0) (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.0) (1.19.5)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-py3-none-any.whl size=16033 sha256=4f3723ef7d75dbc632570d258c4ebad92c6f85c6bf82f82ad7c8f3cc979adc9a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/8c/80/1bf8cc2fa471c320978f34c5290675daaa96446e1b9ba45555\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.7.0\r\n",
      "Processing /kaggle/input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.0\r\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2,math,gc\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.nn import Parameter\n",
    "\n",
    "!pip install \"../input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\"\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "!pip install \"../input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\"\n",
    "import faiss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import cudf, cuml, cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-eagle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:14:44.810242Z",
     "iopub.status.busy": "2021-05-09T23:14:44.809727Z",
     "iopub.status.idle": "2021-05-09T23:14:44.813521Z",
     "shell.execute_reply": "2021-05-09T23:14:44.813045Z"
    },
    "papermill": {
     "duration": 0.027267,
     "end_time": "2021-05-09T23:14:44.813649",
     "exception": false,
     "start_time": "2021-05-09T23:14:44.786382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    img_size = (380,380)\n",
    "    feavec_num1 = 512\n",
    "    feavec_num2 = 1280\n",
    "    fea_norm = 64\n",
    "    margin = 0.35\n",
    "    batch = 50\n",
    "    wpath = [\"../input/shopee-weight/w_eff6_s380_cl8812_fold1_v2.pt\",\n",
    "             \"../input/shopee-weight/w_effb3_s380_cl8811_fold2_0.80.pt\",\n",
    "             \"../input/shopee-weight/w_effb5_s380_cl8811_fold3.pt\",\n",
    "             \"../input/shopee-weight/w_effb4_s380_cl8811_fold4.pt\",\n",
    "             \"../input/shopee-weight/w_effb3_s380_cl8811_fold5_m0.35.pt\"]\n",
    "    mname = ['efficientnet-b6','efficientnet-b3','efficientnet-b5','efficientnet-b4','efficientnet-b3']\n",
    "    clsize = [8812,8811,8811,8811,8811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "actual-citizen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:14:44.859359Z",
     "iopub.status.busy": "2021-05-09T23:14:44.858869Z",
     "iopub.status.idle": "2021-05-09T23:14:51.793443Z",
     "shell.execute_reply": "2021-05-09T23:14:51.792990Z"
    },
    "papermill": {
     "duration": 6.960704,
     "end_time": "2021-05-09T23:14:51.793568",
     "exception": false,
     "start_time": "2021-05-09T23:14:44.832864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape is (3, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPUTE_CV = False\n",
    "\n",
    "#make target clustering\n",
    "if COMPUTE_CV:\n",
    "    df = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['target'] = df['target'].apply(lambda x: ' '.join(x))\n",
    "    df_cu = cudf.DataFrame(df)\n",
    "else:\n",
    "    df = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\n",
    "    df_cu = cudf.DataFrame(df)\n",
    "    if len(df)==3:\n",
    "        cfg.batch = 3\n",
    "    \n",
    "print('df shape is', df.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-cambodia",
   "metadata": {
    "papermill": {
     "duration": 0.019323,
     "end_time": "2021-05-09T23:14:51.834318",
     "exception": false,
     "start_time": "2021-05-09T23:14:51.814995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recorded-hunger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:14:51.887240Z",
     "iopub.status.busy": "2021-05-09T23:14:51.886561Z",
     "iopub.status.idle": "2021-05-09T23:14:51.890233Z",
     "shell.execute_reply": "2021-05-09T23:14:51.889818Z"
    },
    "papermill": {
     "duration": 0.036014,
     "end_time": "2021-05-09T23:14:51.890334",
     "exception": false,
     "start_time": "2021-05-09T23:14:51.854320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.30, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size(), device=device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,name,clustersize,feavec=512):\n",
    "        super(Model, self).__init__()\n",
    "        self.eff = EfficientNet.from_name(name)\n",
    "        self.out = nn.Linear(1000,feavec)\n",
    "        self.margin = ArcMarginProduct(in_features=feavec, \n",
    "                                       out_features = clustersize, \n",
    "                                       s=cfg.fea_norm, \n",
    "                                       m=cfg.margin)      \n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.eff(x)\n",
    "        x = self.out(x)\n",
    "        if labels is not None:\n",
    "            return self.margin(x,labels)\n",
    "        return F.normalize(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instructional-optics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:14:51.937583Z",
     "iopub.status.busy": "2021-05-09T23:14:51.937083Z",
     "iopub.status.idle": "2021-05-09T23:15:00.014685Z",
     "shell.execute_reply": "2021-05-09T23:15:00.013937Z"
    },
    "papermill": {
     "duration": 8.104813,
     "end_time": "2021-05-09T23:15:00.014828",
     "exception": false,
     "start_time": "2021-05-09T23:14:51.910015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Model(name=cfg.mname[0],clustersize=cfg.clsize[0]).to(device).half()\n",
    "model1.load_state_dict(torch.load(cfg.wpath[0], map_location=device))\n",
    "\n",
    "model2 = Model(name=cfg.mname[1],clustersize=cfg.clsize[1]).to(device).half()\n",
    "model2.load_state_dict(torch.load(cfg.wpath[1], map_location=device))\n",
    "\n",
    "model3 = Model(name=cfg.mname[2],clustersize=cfg.clsize[2]).to(device).half()\n",
    "model3.load_state_dict(torch.load(cfg.wpath[2], map_location=device))\n",
    "\n",
    "model4 = Model(name=cfg.mname[3],clustersize=cfg.clsize[3]).to(device).half()\n",
    "model4.load_state_dict(torch.load(cfg.wpath[3], map_location=device))\n",
    "\n",
    "model5 = Model(name=cfg.mname[4],clustersize=cfg.clsize[4]).to(device).half()\n",
    "model5.load_state_dict(torch.load(cfg.wpath[4], map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "material-metadata",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.066862Z",
     "iopub.status.busy": "2021-05-09T23:15:00.064923Z",
     "iopub.status.idle": "2021-05-09T23:15:00.067585Z",
     "shell.execute_reply": "2021-05-09T23:15:00.068020Z"
    },
    "papermill": {
     "duration": 0.031794,
     "end_time": "2021-05-09T23:15:00.068143",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.036349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make image Datasets\n",
    "def load_image(file_name):\n",
    "    if COMPUTE_CV:\n",
    "        file_path = f'/kaggle/input/shopee-product-matching/train_images/{file_name}'\n",
    "    else:\n",
    "        file_path = f'/kaggle/input/shopee-product-matching/test_images/{file_name}'\n",
    "\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, cfg.img_size)\n",
    "    tensor_img = torch.tensor(img)\n",
    "    tensor_img = tensor_img.permute(( 2, 0, 1)).float()/255.0\n",
    "    return tensor_img\n",
    "\n",
    "class valDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.img = df.image.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img[idx]\n",
    "        img = load_image(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "negative-democracy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.124763Z",
     "iopub.status.busy": "2021-05-09T23:15:00.122912Z",
     "iopub.status.idle": "2021-05-09T23:15:00.125635Z",
     "shell.execute_reply": "2021-05-09T23:15:00.126090Z"
    },
    "papermill": {
     "duration": 0.036994,
     "end_time": "2021-05-09T23:15:00.126209",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.089215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_embeddings(df):\n",
    "    dataset = valDataset(df)\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=cfg.batch,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=False)\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    model4.eval()\n",
    "    model5.eval()\n",
    "    print('start collection')\n",
    "    feavec = 512\n",
    "    embedded1 = np.empty((0,feavec),dtype='float32')\n",
    "    embedded2 = np.empty((0,feavec),dtype='float32')\n",
    "    embedded3 = np.empty((0,feavec),dtype='float32')\n",
    "    embedded4 = np.empty((0,feavec),dtype='float32')\n",
    "    embedded5 = np.empty((0,feavec),dtype='float32')\n",
    "    with torch.no_grad():\n",
    "        for idx,images in enumerate(loader):\n",
    "            images = images.to(device,non_blocking=True).half()\n",
    "            outputs = model1(images)\n",
    "            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n",
    "            outputs = model2(images)\n",
    "            embedded2 = np.append(embedded2, outputs.cpu().detach().numpy(),axis=0)\n",
    "            outputs = model3(images)\n",
    "            embedded3 = np.append(embedded3, outputs.cpu().detach().numpy(),axis=0)\n",
    "            outputs = model4(images)\n",
    "            embedded4 = np.append(embedded4, outputs.cpu().detach().numpy(),axis=0)\n",
    "            outputs = model5(images)\n",
    "            embedded5 = np.append(embedded5, outputs.cpu().detach().numpy(),axis=0)\n",
    "\n",
    "            if idx%100==0:\n",
    "                print(idx,len(loader)) \n",
    "                print(embedded1.shape)\n",
    "                print(embedded2.shape)\n",
    "                print(embedded3.shape)\n",
    "                print(embedded4.shape)\n",
    "                print(embedded5.shape)\n",
    "    #del model1,model2,model3,model4\n",
    "    return embedded1,embedded2,embedded3,embedded4,embedded5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affecting-volleyball",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.184707Z",
     "iopub.status.busy": "2021-05-09T23:15:00.183244Z",
     "iopub.status.idle": "2021-05-09T23:15:00.185961Z",
     "shell.execute_reply": "2021-05-09T23:15:00.186373Z"
    },
    "papermill": {
     "duration": 0.039083,
     "end_time": "2021-05-09T23:15:00.186489",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.147406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "def predict_img(df,embeddings,topk=50,threshold=0.63):\n",
    "    N,D = embeddings.shape\n",
    "    cpu_index = faiss.IndexFlatL2(D)\n",
    "    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n",
    "    gpu_index.add(embeddings)\n",
    "    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n",
    "    \n",
    "    df['pred_images'] = ''\n",
    "    pred = []\n",
    "    for k in range(embeddings.shape[0]):\n",
    "        idx = np.where(cluster_distance[k,] < threshold)[0]\n",
    "        ids = cluster_index[k,idx]\n",
    "        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "        posting_ids = df['posting_id'].iloc[ids].values\n",
    "        pred.append(posting_ids)\n",
    "    df['pred_images'] = pred\n",
    "    if COMPUTE_CV:\n",
    "        df['pred_imgonly'] = df.pred_images.apply(lambda x: ' '.join(x))\n",
    "        df['f1_img'] = f1_score(df['target'], df['pred_imgonly'])\n",
    "        score = df['f1_img'].mean()\n",
    "        print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "    return df\n",
    "\n",
    "def predict_text(df,embeddings,topk=50,threshold=0.63):\n",
    "    N,D = embeddings.shape\n",
    "    cpu_index = faiss.IndexFlatL2(D)\n",
    "    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n",
    "    gpu_index.add(embeddings)\n",
    "    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n",
    "    \n",
    "    df['pred_text'] = ''\n",
    "    pred = []\n",
    "    for k in range(embeddings.shape[0]):\n",
    "        idx = np.where(cluster_distance[k,] < threshold)[0]\n",
    "        ids = cluster_index[k,idx]\n",
    "        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "        posting_ids = df['posting_id'].iloc[ids].values\n",
    "        pred.append(posting_ids)\n",
    "    df['pred_text'] = pred\n",
    "    if COMPUTE_CV:\n",
    "        df['pred_textonly'] = df.pred_images.apply(lambda x: ' '.join(x))\n",
    "        df['f1_text'] = f1_score(df['target'], df['pred_textonly'])\n",
    "        score = df['f1_text'].mean()\n",
    "        print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-observation",
   "metadata": {
    "papermill": {
     "duration": 0.022491,
     "end_time": "2021-05-09T23:15:00.231762",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.209271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incident-touch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.288993Z",
     "iopub.status.busy": "2021-05-09T23:15:00.287424Z",
     "iopub.status.idle": "2021-05-09T23:15:00.289820Z",
     "shell.execute_reply": "2021-05-09T23:15:00.290229Z"
    },
    "papermill": {
     "duration": 0.0355,
     "end_time": "2021-05-09T23:15:00.290348",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.254848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, max_features = 25000,threshold=0.7):\n",
    "    from cuml.feature_extraction.text import TfidfVectorizer\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu.title).toarray()\n",
    "    #print(text_embeddings)\n",
    "    preds = []\n",
    "    CHUNK = 1024*4\n",
    "\n",
    "    print('Finding similar titles...')\n",
    "    CTS = len(df)//CHUNK\n",
    "    if len(df)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(df))\n",
    "        print('chunk',a,'to',b)\n",
    "\n",
    "        # COSINE SIMILARITY DISTANCE\n",
    "        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]>threshold)[0]\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "    df['pred_text'] = preds\n",
    "    del model,text_embeddings\n",
    "    gc.collect()\n",
    "    if COMPUTE_CV:\n",
    "        df['pred_textonly'] = df.pred_text.apply(lambda x: ' '.join(x))\n",
    "        df['f1_text'] = f1_score(df['target'], df['pred_textonly'])\n",
    "        score = df['f1_text'].mean()\n",
    "        print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-preliminary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.352653Z",
     "iopub.status.busy": "2021-05-09T23:15:00.348126Z",
     "iopub.status.idle": "2021-05-09T23:15:00.354744Z",
     "shell.execute_reply": "2021-05-09T23:15:00.355285Z"
    },
    "papermill": {
     "duration": 0.042447,
     "end_time": "2021-05-09T23:15:00.355437",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.312990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class textvalDataset(Dataset):\n",
    "    def __init__(self, textlist):\n",
    "        self.text = textlist\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = torch.tensor(self.text[idx])\n",
    "        text = text.float()\n",
    "        return text\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,clustersize,feavec=512):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(24939,4000)\n",
    "        self.linear2 = nn.Linear(4000,feavec)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.margin = ArcMarginProduct(in_features=feavec, \n",
    "                                       out_features = clustersize, \n",
    "                                       s=64, \n",
    "                                       m=0.7)      \n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.linear1(x)\n",
    "        #x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        #x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        if labels is not None:\n",
    "            return self.margin(x,labels)\n",
    "        return F.normalize(x,dim=1)\n",
    "    \n",
    "\n",
    "def get_deeptext_predictions(df):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    df_t = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n",
    "    models = TfidfVectorizer(stop_words = 'english', binary = True, max_features = 24939)\n",
    "    models.fit(pd.concat([df,df_t],axis=0).title)\n",
    "    text = models.transform(df.title).toarray()\n",
    "    batch = 100\n",
    "    if len(df)==3:\n",
    "        batch=3\n",
    "    test_dataset = textvalDataset(text)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch,\n",
    "                            shuffle=False,\n",
    "                            num_workers=2,\n",
    "                            pin_memory=True)\n",
    "    model_t1 = Model(8811)\n",
    "    model_t2 = Model(8811)\n",
    "    model_t1 = model_t1.to(device)\n",
    "    model_t2 = model_t2.to(device)\n",
    "    model_t1.load_state_dict(torch.load('../input/shopee-weight/w_lin_e5_fold1.pt'))\n",
    "    model_t2.load_state_dict(torch.load('../input/shopee-weight/w_lin_e5_fold2.pt'))\n",
    "    #model.load_state_dict(torch.load('../input/shopee-weight-text/w_lin_e5_fold0.pt'))\n",
    "    model_t1.eval()\n",
    "    model_t2.eval()\n",
    "    print('start collection')\n",
    "    embedded1 = np.empty((0,512),dtype='float32')\n",
    "    embedded2 = np.empty((0,512),dtype='float32')\n",
    "    with torch.no_grad():\n",
    "        for idx,(images) in enumerate(test_loader):\n",
    "            images = images.to(device,non_blocking=True)\n",
    "            outputs = model_t1(images)\n",
    "            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n",
    "            outputs = model_t2(images)\n",
    "            embedded2 = np.append(embedded2, outputs.cpu().detach().numpy(),axis=0)\n",
    "\n",
    "            if idx%100==0:\n",
    "                print(idx,len(test_loader)) \n",
    "                print(embedded1.shape)\n",
    "                print(embedded2.shape)\n",
    "    print(embedded1.shape,embedded2.shape)\n",
    "    return embedded1,embedded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "super-settle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:00.405135Z",
     "iopub.status.busy": "2021-05-09T23:15:00.404468Z",
     "iopub.status.idle": "2021-05-09T23:15:09.814526Z",
     "shell.execute_reply": "2021-05-09T23:15:09.815115Z"
    },
    "papermill": {
     "duration": 9.436836,
     "end_time": "2021-05-09T23:15:09.815318",
     "exception": false,
     "start_time": "2021-05-09T23:15:00.378482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start collection\n",
      "0 1\n",
      "(3, 512)\n",
      "(3, 512)\n",
      "(3, 512) (3, 512)\n"
     ]
    }
   ],
   "source": [
    "text_embeddings1, text_embeddings2 = get_deeptext_predictions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-steps",
   "metadata": {
    "papermill": {
     "duration": 0.021218,
     "end_time": "2021-05-09T23:15:09.859094",
     "exception": false,
     "start_time": "2021-05-09T23:15:09.837876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Carry out image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-crack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:09.919921Z",
     "iopub.status.busy": "2021-05-09T23:15:09.918406Z",
     "iopub.status.idle": "2021-05-09T23:15:12.303890Z",
     "shell.execute_reply": "2021-05-09T23:15:12.304452Z"
    },
    "papermill": {
     "duration": 2.424258,
     "end_time": "2021-05-09T23:15:12.304640",
     "exception": false,
     "start_time": "2021-05-09T23:15:09.880382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start collection\n",
      "0 1\n",
      "(3, 512)\n",
      "(3, 512)\n",
      "(3, 512)\n",
      "(3, 512)\n",
      "(3, 512)\n"
     ]
    }
   ],
   "source": [
    "image_embeddings1,image_embeddings2,image_embeddings3, image_embeddings4, image_embeddings5 = image_embeddings(df)\n",
    "\n",
    "#image_embeddings2 = image_embeddings(df,cfg.wpath2,cfg.mname2,cfg.feavec_num1)\n",
    "#image_embeddings3 = image_embeddings(df,cfg.wpath3,cfg.mname3,cfg.feavec_num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indirect-constant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.356175Z",
     "iopub.status.busy": "2021-05-09T23:15:12.355513Z",
     "iopub.status.idle": "2021-05-09T23:15:12.359701Z",
     "shell.execute_reply": "2021-05-09T23:15:12.359291Z"
    },
    "papermill": {
     "duration": 0.03129,
     "end_time": "2021-05-09T23:15:12.359810",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.328520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_reuse = False\n",
    "if embed_reuse:\n",
    "    image_embeddings1 = np.load(\"../input/shopeeinferoutput/fold1_512.npy\")\n",
    "    image_embeddings2 = np.load(\"../input/shopeeinferoutput/fold2_512.npy\")\n",
    "    image_embeddings3 = np.load(\"../input/shopeeinferoutput/fold3_512.npy\")\n",
    "    image_embeddings4 = np.load(\"../input/shopeeinferoutput/fold4_512.npy\")\n",
    "    image_embeddings5 = np.load(\"../input/shopeeinferoutput/fold5_512.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worth-basin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.413663Z",
     "iopub.status.busy": "2021-05-09T23:15:12.411786Z",
     "iopub.status.idle": "2021-05-09T23:15:12.414321Z",
     "shell.execute_reply": "2021-05-09T23:15:12.414770Z"
    },
    "papermill": {
     "duration": 0.032392,
     "end_time": "2021-05-09T23:15:12.414897",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.382505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = np.array([1.2,0.8,1.1,0.8,0.7])\n",
    "image_embeddings = (w[0]*image_embeddings1+w[1]*image_embeddings2+w[2]*image_embeddings3+w[3]*image_embeddings4+w[4]*image_embeddings5)/w.sum()\n",
    "wt = np.array([1,1])\n",
    "text_embeddings = (wt[0]*text_embeddings1+wt[1]*text_embeddings2)/wt.sum()\n",
    "img_text_embeddings = (image_embeddings + 0.4*text_embeddings)/1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deadly-ghost",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.468833Z",
     "iopub.status.busy": "2021-05-09T23:15:12.467063Z",
     "iopub.status.idle": "2021-05-09T23:15:12.469375Z",
     "shell.execute_reply": "2021-05-09T23:15:12.469789Z"
    },
    "papermill": {
     "duration": 0.031251,
     "end_time": "2021-05-09T23:15:12.469907",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.438656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_embeddings = np.average([image_embeddings1, image_embeddings2, image_embeddings3, image_embeddings4, image_embeddings5], axis = 0)\n",
    "#w = np.array([0.80,1.05,1.4,1.05,1.15])\n",
    "#image_embeddings = np.average([image_embeddings2, image_embeddings3, image_embeddings4], axis = 0)\n",
    "#image_embeddings = np.average([image_embeddings3, image_embeddings4], axis = 0)\n",
    "if COMPUTE_CV:\n",
    "    df = predict_img(df,image_embeddings1,topk=50,threshold=0.88)\n",
    "    df = predict_img(df,image_embeddings2,topk=50,threshold=0.88)\n",
    "    df = predict_img(df,image_embeddings3,topk=50,threshold=0.88)\n",
    "    df = predict_img(df,image_embeddings4,topk=50,threshold=0.88)\n",
    "    df = predict_img(df,image_embeddings5,topk=50,threshold=0.88)\n",
    "    df = predict_img(df,image_embeddings,topk=50,threshold=0.196)\n",
    "    df = predict_img(df,img_text_embeddings,topk=50,threshold=0.138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "public-beauty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.520998Z",
     "iopub.status.busy": "2021-05-09T23:15:12.519271Z",
     "iopub.status.idle": "2021-05-09T23:15:12.521616Z",
     "shell.execute_reply": "2021-05-09T23:15:12.522057Z"
    },
    "papermill": {
     "duration": 0.02966,
     "end_time": "2021-05-09T23:15:12.522175",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.492515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    np.save('fold1_512.npy', image_embeddings1)\n",
    "    np.save('fold2_512.npy', image_embeddings2)\n",
    "    np.save('fold3_512.npy', image_embeddings3)\n",
    "    np.save('fold4_512.npy', image_embeddings4)\n",
    "    np.save('fold5_512.npy', image_embeddings5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "composed-budapest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.571602Z",
     "iopub.status.busy": "2021-05-09T23:15:12.570918Z",
     "iopub.status.idle": "2021-05-09T23:15:12.881077Z",
     "shell.execute_reply": "2021-05-09T23:15:12.880584Z"
    },
    "papermill": {
     "duration": 0.336677,
     "end_time": "2021-05-09T23:15:12.881206",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.544529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2,3,4\n",
    "#df = predict_img(df,image_embeddings,topk=50,threshold=0.13)\n",
    "df = predict_img(df,img_text_embeddings,topk=50,threshold=0.12)\n",
    "#3,4\n",
    "#df = predict_img(df,image_embeddings,topk=50,threshold=0.30)\n",
    "\n",
    "#df = predict_img(df,image_embeddings,topk=50,threshold=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "listed-cowboy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:12.933081Z",
     "iopub.status.busy": "2021-05-09T23:15:12.932445Z",
     "iopub.status.idle": "2021-05-09T23:15:12.936718Z",
     "shell.execute_reply": "2021-05-09T23:15:12.936257Z"
    },
    "papermill": {
     "duration": 0.032168,
     "end_time": "2021-05-09T23:15:12.936840",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.904672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "theresholds=np.linspace(0.13,0.15,10)\n",
    "if COMPUTE_CV:\n",
    "    #for topk in [49,50,51,60]:\n",
    "    for threshold in theresholds:\n",
    "        df = predict_img(df,img_text_embeddings,topk=50,threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-brisbane",
   "metadata": {
    "papermill": {
     "duration": 0.02402,
     "end_time": "2021-05-09T23:15:12.983827",
     "exception": false,
     "start_time": "2021-05-09T23:15:12.959807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Carry out text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "normal-australia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:13.037052Z",
     "iopub.status.busy": "2021-05-09T23:15:13.036210Z",
     "iopub.status.idle": "2021-05-09T23:15:27.300856Z",
     "shell.execute_reply": "2021-05-09T23:15:27.300330Z"
    },
    "papermill": {
     "duration": 14.292761,
     "end_time": "2021-05-09T23:15:27.300994",
     "exception": false,
     "start_time": "2021-05-09T23:15:13.008233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar titles...\n",
      "chunk 0 to 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>pred_images</th>\n",
       "      <th>pred_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title        pred_images  \\\n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  [test_2255846744]   \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  [test_3588702337]   \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  [test_4015706929]   \n",
       "\n",
       "           pred_text  \n",
       "0  [test_2255846744]  \n",
       "1  [test_3588702337]  \n",
       "2  [test_4015706929]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_text_predictions(df, max_features = 25000,threshold=0.75)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-funds",
   "metadata": {
    "papermill": {
     "duration": 0.023345,
     "end_time": "2021-05-09T23:15:27.348508",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.325163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# combine_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "metric-exclusion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:27.399598Z",
     "iopub.status.busy": "2021-05-09T23:15:27.399106Z",
     "iopub.status.idle": "2021-05-09T23:15:27.402837Z",
     "shell.execute_reply": "2021-05-09T23:15:27.402363Z"
    },
    "papermill": {
     "duration": 0.030898,
     "end_time": "2021-05-09T23:15:27.403015",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.372117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['pred_images'], row['pred_text']])\n",
    "    return ' '.join( np.unique(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "regulated-latin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:27.456153Z",
     "iopub.status.busy": "2021-05-09T23:15:27.455618Z",
     "iopub.status.idle": "2021-05-09T23:15:27.464176Z",
     "shell.execute_reply": "2021-05-09T23:15:27.463746Z"
    },
    "papermill": {
     "duration": 0.037805,
     "end_time": "2021-05-09T23:15:27.464278",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.426473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['matches'] = df.apply(combine_predictions, axis=1)\n",
    "#df['matches'] = df['pred_images'].apply(lambda x: ' '.join(x))\n",
    "if COMPUTE_CV:\n",
    "    df['f1'] = f1_score(df['target'], df['matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Final f1 score is {score}')\n",
    "else:\n",
    "    with open('submission.csv', 'w') as outf:\n",
    "        print('posting_id,matches', file=outf)\n",
    "        for i,(idnum,match) in enumerate(zip(df['posting_id'],df['matches'])):\n",
    "            print(f'{idnum},{match}', file=outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "greenhouse-format",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:15:27.515285Z",
     "iopub.status.busy": "2021-05-09T23:15:27.514611Z",
     "iopub.status.idle": "2021-05-09T23:15:27.517480Z",
     "shell.execute_reply": "2021-05-09T23:15:27.516943Z"
    },
    "papermill": {
     "duration": 0.029096,
     "end_time": "2021-05-09T23:15:27.517586",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.488490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_t = pd.read_csv(\"submission.csv\")\n",
    "# print(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-lighting",
   "metadata": {
    "papermill": {
     "duration": 0.023381,
     "end_time": "2021-05-09T23:15:27.564620",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.541239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-girlfriend",
   "metadata": {
    "papermill": {
     "duration": 0.02358,
     "end_time": "2021-05-09T23:15:27.612131",
     "exception": false,
     "start_time": "2021-05-09T23:15:27.588551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 115.905053,
   "end_time": "2021-05-09T23:15:30.436883",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-09T23:13:34.531830",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
